\section*{Introducción}

El estudio de la solución de la optmización de una función cuadratica de la forma

\begin{equation}
    f(x) = \frac{1}{2}x^TAx- b^Tx \label{eq:quadratic_function}
\end{equation}

donde $b\in\mathbb{R}^n$ y $A$ es una matriz positiva definida en $\mathbb{R}^{n\times n}$, es equivalente a la solución del sistema de ecuaciones

\begin{equation*}
    Ax=b
\end{equation*}

El problema empieza a tener dificultades cuando el tamaño de la matriz aumenta y esta contiene ceros en sus elementos (caso sparce). Esto provoca que la factorización por Cholesky sea impráctica por el tiempo de ejecucción o el espacio en memoria.  En 1988 Barzilai y Borwein propusieron dos tamaños de paso para mejorar el desempeño de métodos de descenso de gradiente. La elección de los tamaños de paso propuestos estan basados en métodos Cuasi-Newton. Donde $\alpha_k$ es remplazada por la matriz $D_k$ tal que

\begin{equation}
    D_k = \alpha_k \mathit{I}
\end{equation}

La matriz $D_k$ es una aproximación de la inversa del hessiano. El tamaño de paso es calculado a partir de la optimización de $D_k^{-1}$  (BB1) y  $D_k$ (BB2) tal que satisfagan la ecuación de la secante desde un punto de vista de mínimos cuadrados (ecuación \ref{eq:definition_barzilai}).

\begin{equation}
    \min_{D=\alpha \mathit{I}} ||D^{-1}s_{k-1}-y_{k-1}|| \qquad \min_{D=\alpha \mathit{I}} ||s_{k-1}-Dy_{k-1}|| \label{eq:definition_barzilai}
\end{equation}

donde $s_{k-1} = x_k - x_{k-1}$ y $y_{k-1} = g_k - g_{k-1}$.

Las soluciones del problema son las descritas en la ecuación \ref{eq:barzilai_steps}.

\begin{equation}
    \alpha^{BB1}_k = \frac{s^T_{k-1}s_{k-1}}{s^T_{k-1}y_{k-1}} \qquad \alpha_k^{BB2} = \frac{s_{k-1}^Ty_{k-1}}{y_{k-1}^Ty_{k-1}} \label{eq:barzilai_steps}
\end{equation}

% desigualdad de Cauchy-Schwarz $\|s_{k-1}\|^2\|y_{k-1}\|^2 \geq (s_{k-1}^Ty_{k-1})^2$
Considerando la desigualdad de Cauchy-Schwarz observa que cuando $s_{k-1}^Ty_{k-1}$ es mayor a cero, entonces se cumple que $\alpha_k^{BB1} \geq \alpha_k^{BB2}$. Esto por ello, que se suele llamar paso largo e Barzilai-Borwein al paso $\alpha_k^{BB1}$ y paso corto a $\alpha_k^{BB2}$. Para una función cuadrática, el paso $\alpha_k^{BB1}$ es el tamaño de paso de máximo descenso con retardo de un paso y $\alpha_k^{BB2}$ será el paso del método de mínimo gradiente. En 1993, Raydan demuestra la convergencia del método para el caso cuadrático\cite{raydan_1993}, y en 1997 introdujó una estrategia global basada en una búsqueda lineal no monótona, la cual establece la convergencia global para el método de Barzilai-Borwein (BB) para los casos no cuadráticos. El método BB no asegura la convergencia cuando la función objetivo es fuertemente convexa. Para ello existen varios métodos para estabilizar la convergencia del problema. Uno de los métodos para estabilizar a estos métodos es la elección del tamaño de paso en cada iteración de la siguiente forma:

\begin{equation}
    \alpha_k = \min \alpha_k^{BB}, \Delta
\end{equation}

donde $\Delta$ es un valor fijo. En el artículo de Oleg Burdakov\cite{burdakob_2019} realiza varios experimentos con esta estrategia y obtuvo que para la función de rosembrock, el valor de $\Delta$ con mejores resultados fue 0.1. Por esta misma razón se siguen explorando estrategias que complementen al método BB para la convergencia global en funciones fuertemente convexas.